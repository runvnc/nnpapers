I'm trying to learn some basics about neural networks.

I have found many tutorials online.

However, I discovered that as far as understanding the most basic aspects of these things from
the perspective of a programmer trying to code them (or just someone trying to understand the core details of how they work), the original papers seem to explain them more clearly than most tutorials.  Going back to like 1986 or 1999 for example.

## Backpropagation

[Learning Representations by Back-propagating Errors](hinton86.pdf)


## Convolution

[Object Recognition with Gradient-Based Learning](lecun99.pdf)


